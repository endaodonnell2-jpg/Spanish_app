<!DOCTYPE html>
<html lang="en">
<head>
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Walkie-Talkie Mobile</title>
<style>
  body {
    margin: 0;
    font-family: sans-serif;
    display: flex;
    flex-direction: column;
    height: 100vh;
    background: #f5f1e6; /* light beige */
    color: #000;
    overflow: hidden;
  }

  /* Waveform bars container */
  #waveforms {
    display: flex;
    justify-content: space-around;
    gap: 10px;
    height: 20%;
    padding: 5px 10px;
    box-sizing: border-box;
  }

  .bar-container {
    flex: 1;
    display: flex;
    align-items: flex-end;
    gap: 2px;
  }

  .bar {
    flex: 1;
    background: #ccc;
    border-radius: 2px;
    height: 20px;
    transition: height 0.05s;
  }

  /* Text area */
  #textArea {
    flex: 1;
    padding: 5px 10px;
    overflow-y: auto;
    background: #faf5ec;
    font-size: 0.9rem;
    line-height: 1.2rem;
    border-top: 1px solid #ddd;
    border-bottom: 1px solid #ddd;
  }

  .userText { color: #d9534f; margin: 2px 0; }
  .aiText { color: #5cb85c; margin: 2px 0; }

  /* Hold to talk button */
  #talkBtn {
    height: 15%;
    margin: 5px 10px;
    border: none;
    border-radius: 12px;
    font-size: 1.2rem;
    background: #5cb85c;
    color: #fff;
    transition: background 0.2s, transform 0.1s;
    display: flex;
    justify-content: center;
    align-items: center;
  }

  #talkBtn.active {
    background: #d9534f;
    transform: scale(1.05);
  }
</style>
</head>
<body>

<!-- Waveforms -->
<div id="waveforms">
  <div id="userBars" class="bar-container"></div>
  <div id="aiBars" class="bar-container"></div>
</div>

<!-- Text area -->
<div id="textArea"></div>

<!-- Hold-to-talk button -->
<button id="talkBtn">Hold to Talk</button>

<script>
const talkBtn = document.getElementById('talkBtn');
const textArea = document.getElementById('textArea');
const userBarsContainer = document.getElementById('userBars');
const aiBarsContainer = document.getElementById('aiBars');

let mediaRecorder, audioChunks = [];
let isRecording = false;

// Create waveform bars
const createBars = (container, color) => {
  const bars = [];
  for(let i=0; i<20; i++) {
    const bar = document.createElement('div');
    bar.classList.add('bar');
    bar.style.background = color;
    container.appendChild(bar);
    bars.push(bar);
  }
  return bars;
};

const userBars = createBars(userBarsContainer, '#d9534f');
const aiBars = createBars(aiBarsContainer, '#5cb85c');

// Animate bars with real audio data
const animateBars = (bars, volume) => {
  bars.forEach((bar, i) => {
    const variance = Math.random() * 0.3; // add wobble
    const height = Math.min(5 + (volume + variance) * 60, 60);
    bar.style.height = `${height}px`;
  });
};

// Start recording
async function startRecording() {
  isRecording = true;
  talkBtn.classList.add('active');

  textArea.innerHTML += `<div class="userText">You: ...</div>`;
  textArea.scrollTop = textArea.scrollHeight;

  const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
  mediaRecorder = new MediaRecorder(stream);
  audioChunks = [];
  mediaRecorder.ondataavailable = e => audioChunks.push(e.data);
  mediaRecorder.start();

  const audioContext = new AudioContext();
  const source = audioContext.createMediaStreamSource(stream);
  const analyser = audioContext.createAnalyser();
  source.connect(analyser);
  analyser.fftSize = 256;
  const dataArray = new Uint8Array(analyser.frequencyBinCount);

  // Animate user bars live
  function update() {
    if(!isRecording) return;
    analyser.getByteFrequencyData(dataArray);
    const avg = dataArray.reduce((a,b)=>a+b,0)/dataArray.length/255;
    animateBars(userBars, avg);
    requestAnimationFrame(update);
  }
  update();
}

// Stop recording
async function stopRecording() {
  if(!mediaRecorder) return;
  isRecording = false;
  talkBtn.classList.remove('active');
  mediaRecorder.stop();
  mediaRecorder.onstop = async () => {
    const blob = new Blob(audioChunks, { type: 'audio/webm' });
    const formData = new FormData();
    formData.append('file', blob, 'talk.webm');

    try {
      const response = await fetch('/process_audio', { method: 'POST', body: formData });
      const data = await response.json();
      const aiAudio = new Audio(data.tts_url);

      // Animate AI bars while playing
      aiAudio.onplay = () => {
        const aiLine = document.createElement('div');
        aiLine.classList.add('aiText');
        aiLine.textContent = 'AI: ...';
        textArea.appendChild(aiLine);
        textArea.scrollTop = textArea.scrollHeight;

        const aiInterval = setInterval(() => {
          animateBars(aiBars, Math.random());
        }, 50);

        aiAudio.onended = () => {
          clearInterval(aiInterval);
        };
      };
      aiAudio.play();
    } catch(e) {
      console.error('Error processing audio', e);
      alert('Failed to process audio');
    }
  }
}

// Button events
talkBtn.addEventListener('mousedown', startRecording);
talkBtn.addEventListener('mouseup', stopRecording);
talkBtn.addEventListener('touchstart', e => { e.preventDefault(); startRecording(); });
talkBtn.addEventListener('touchend', e => { e.preventDefault(); stopRecording(); });
</script>
</body>
</html>
