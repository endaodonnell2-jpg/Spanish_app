<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
<title>Lucas11</title>

<style>
:root {
    --bg: #f3efe7;
    --green1: #3df58a;
    --green2: #18b45c;
    --red1: #ff5a5a;
    --red2: #b30000;
    --grey: #bbbbbb;
    --gear-color: rgba(0,0,0,0.2);
}

* {
    box-sizing: border-box;
    user-select: none;
    -webkit-user-select: none;
    -webkit-touch-callout: none;
    -webkit-tap-highlight-color: transparent;
}

body {
    margin: 0;
    background: var(--bg);
    height: 100vh;
    display: flex;
    flex-direction: column;
    justify-content: center;
    align-items: center;
    overflow: hidden;
    font-family: -apple-system, system-ui, sans-serif;
}

#visualizer {
    width: 90%;
    height: 100px;
    margin-bottom: 60px;
}

#micBtn {
    width: 140px;
    height: 140px;
    border-radius: 50%;
    display: flex;
    align-items: center;
    justify-content: center;
    cursor: pointer;
    background: radial-gradient(circle at 30% 30%, var(--green1), var(--green2));
    box-shadow:
        0 15px 30px rgba(0,0,0,0.25),
        inset 0 6px 10px rgba(255,255,255,0.4),
        inset 0 -8px 15px rgba(0,0,0,0.3);
    transition:
        transform 0.18s cubic-bezier(.34,1.56,.64,1),
        box-shadow 0.18s ease,
        background 0.2s ease;
    position: relative;
    animation: idleGlow 3s ease-in-out infinite alternate;
}

@keyframes idleGlow {
    0% { box-shadow: 0 15px 30px rgba(0,0,0,0.25), inset 0 6px 10px rgba(255,255,255,0.4), inset 0 -8px 15px rgba(0,0,0,0.3); }
    100% { box-shadow: 0 18px 36px rgba(0,0,0,0.28), inset 0 6px 10px rgba(255,255,255,0.45), inset 0 -8px 15px rgba(0,0,0,0.32); }
}

#micBtn.active {
    background: radial-gradient(circle at 30% 30%, var(--red1), var(--red2));
    animation: none;
}

#micBtn.pressed {
    transform: scale(0.92);
    box-shadow: 0 6px 15px rgba(0,0,0,0.35), inset 0 8px 15px rgba(0,0,0,0.5);
}

#micBtn.pop {
    animation: popEffect 0.25s ease;
}

@keyframes popEffect {
    0% { transform: scale(0.92); }
    60% { transform: scale(1.06); }
    100% { transform: scale(1); }
}

#micBtn svg {
    width: 60%;
    height: 60%;
    fill: white;
    pointer-events: none;
    filter: drop-shadow(0 3px 4px rgba(0,0,0,0.4));
}

#micBtn .gear {
    position: absolute;
    top: -25px;
    right: -10px;
    width: 20px;
    height: 20px;
    opacity: 0;
    transition: opacity 0.2s ease;
    fill: var(--gear-color);
}

#micBtn.thinking .gear {
    opacity: 1;
    animation: spinGear 1s linear infinite;
}

@keyframes spinGear {
    0% { transform: rotate(0deg); }
    100% { transform: rotate(360deg); }
}
</style>
</head>

<body>

<canvas id="visualizer"></canvas>

<div id="micBtn">
    <svg viewBox="0 0 24 24">
        <path d="M12 14a3 3 0 003-3V5a3 3 0 10-6 0v6a3 3 0 003 3zm5-3a1 1 0 10-2 0 3 3 0 01-6 0 1 1 0 10-2 0 5 5 0 004 4.9V19H9a1 1 0 000 2h6a1 1 0 000-2h-2v-3.1A5 5 0 0017 11z"/>
    </svg>
    <svg class="gear" viewBox="0 0 24 24">
        <path d="M19.43 12.98l1.77-1.03-1.77-1.03a7.987 7.987 0 00-.37-1.82l2.11-1.18-1.77-3.06-2.11 1.18a7.978 7.978 0 00-1.54-1.06L14.9 2h-5.8l-.42 2.06c-.57.23-1.1.57-1.54 1.06L5.03 4.95 3.26 8l2.11 1.18c-.12.59-.18 1.2-.12 1.82L3.48 12.98l1.77 1.03c.06.62.12 1.23.24 1.82l-2.11 1.18 1.77 3.06 2.11-1.18c.44.49.97.83 1.54 1.06L9.1 22h5.8l.42-2.06c.57-.23 1.1-.57 1.54-1.06l2.11 1.18 1.77-3.06-2.11-1.18c.12-.59.18-1.2.12-1.82zM12 15.5a3.5 3.5 0 110-7 3.5 3.5 0 010 7z"/>
    </svg>
</div>

<script>
document.addEventListener("DOMContentLoaded", () => {

const canvas = document.getElementById("visualizer");
const micBtn = document.getElementById("micBtn");

if (!canvas || !micBtn) return;

const ctx = canvas.getContext("2d");

let audioCtx;
let analyser;
let dataArray;
let mediaRecorder;
let audioChunks = [];
let state = "idle";
let pressStartTime = 0;
let currentAudio = null;
let currentSource = null;
let currentController = null;
let latestRequestId = 0;

/* ---------------- AUDIO CONTEXT ---------------- */
async function ensureAudioRunning() {
    if (!audioCtx) {
        audioCtx = new (window.AudioContext || window.webkitAudioContext)();
    }
    if (audioCtx.state === "suspended") {
        await audioCtx.resume();
    }
}
window.addEventListener("pointerdown", ensureAudioRunning);
window.addEventListener("touchstart", ensureAudioRunning);

/* ---------------- CLEANUP ---------------- */
function stopCurrentAudio() {
    if (currentAudio) {
        currentAudio.pause();
        currentAudio.src = "";
        currentAudio.load();
        currentAudio = null;
    }
    if (currentSource) {
        try { currentSource.disconnect(); } catch {}
        currentSource = null;
    }
}
function cancelRequest() {
    if (currentController) {
        currentController.abort();
        currentController = null;
    }
}

/* ---------------- CANVAS ---------------- */
function drawFlatLine() {
    ctx.clearRect(0, 0, canvas.width, canvas.height);
    ctx.lineWidth = 2;
    ctx.strokeStyle = "#bbbbbb";
    ctx.beginPath();
    ctx.moveTo(0, canvas.height / 2);
    ctx.lineTo(canvas.width, canvas.height / 2);
    ctx.stroke();
}
function resizeCanvas() {
    canvas.width = canvas.offsetWidth;
    canvas.height = canvas.offsetHeight;
}
resizeCanvas();
window.addEventListener("resize", resizeCanvas);
drawFlatLine();

/* ---------------- RECORDING ---------------- */
micBtn.addEventListener("pointerdown", async (e) => {
    e.stopPropagation();
    await ensureAudioRunning();
    stopCurrentAudio();
    cancelRequest();

    state = "user";
    micBtn.classList.add("active", "pressed");
    pressStartTime = performance.now();
    audioChunks = [];

    const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
    const source = audioCtx.createMediaStreamSource(stream);
    startVisualizer(source);

    mediaRecorder = new MediaRecorder(stream);
    mediaRecorder.ondataavailable = e => audioChunks.push(e.data);
    mediaRecorder.onstop = sendAudio;
    mediaRecorder.start();
});

function stopRecording() {
    const pressDuration = performance.now() - pressStartTime;
    if (mediaRecorder && mediaRecorder.state === "recording") {
        mediaRecorder.stop();
    }
    micBtn.classList.remove("pressed");
    if (pressDuration < 200) {
        audioChunks = [];
        micBtn.classList.remove("active");
        state = "idle";
        return;
    }
    micBtn.classList.add("pop");
    setTimeout(() => micBtn.classList.remove("pop"), 250);
    micBtn.classList.remove("active");
    state = "thinking";
    micBtn.classList.add("thinking");
}
window.addEventListener("pointerup", stopRecording);
window.addEventListener("pointercancel", stopRecording);
window.addEventListener("pointerleave", stopRecording);

/* ---------------- SEND TO BACKEND ---------------- */
async function sendAudio() {
    const blob = new Blob(audioChunks, { type: "audio/webm" });
    if (blob.size < 1000) {
        state = "idle";
        micBtn.classList.remove("thinking");
        return;
    }
    const formData = new FormData();
    formData.append("file", blob, "user.webm");

    const requestId = ++latestRequestId;
    currentController = new AbortController();

    try {
        const response = await fetch("/process_audio", {
            method: "POST",
            body: formData,
            signal: currentController.signal
        });
        const data = await response.json();
        if (requestId === latestRequestId && data.tts_url) {
            playAI(data.tts_url);
        }
    } catch (err) {
        if (err.name !== "AbortError") console.error("Request error:", err);
    }
}

/* ---------------- AI PLAYBACK ---------------- */
function playAI(url) {
    stopCurrentAudio();
    state = "ai";
    micBtn.classList.remove("thinking");

    const audio = new Audio(url + "?t=" + Date.now());
    audio.crossOrigin = "anonymous";
    currentAudio = audio;

    const source = audioCtx.createMediaElementSource(audio);
    const analyserNode = audioCtx.createAnalyser();
    analyserNode.fftSize = 2048;
    source.connect(analyserNode);
    analyserNode.connect(audioCtx.destination);

    analyser = analyserNode;
    dataArray = new Uint8Array(analyser.fftSize);

    function draw() {
        if (state !== "ai") return;
        requestAnimationFrame(draw);
        ctx.clearRect(0, 0, canvas.width, canvas.height);
        analyser.getByteTimeDomainData(dataArray);
        ctx.lineWidth = 3;
        ctx.strokeStyle = "#2ecc71";
        ctx.beginPath();
        const sliceWidth = canvas.width / dataArray.length;
        let x = 0;
        for (let i = 0; i < dataArray.length; i++) {
            const v = dataArray[i] / 128.0;
            const y = v * canvas.height / 2;
            if (i === 0) ctx.moveTo(x, y);
            else ctx.lineTo(x, y);
            x += sliceWidth;
        }
        ctx.stroke();
    }
    draw();

    audio.onended = () => { state = "idle"; };
    audio.play().catch(err => console.log("Playback error:", err));
}

/* ---------------- VISUALIZER ---------------- */
function startVisualizer(sourceNode) {
    analyser = audioCtx.createAnalyser();
    analyser.fftSize = 2048;
    sourceNode.connect(analyser);

    const bufferLength = analyser.fftSize;
    dataArray = new Uint8Array(bufferLength);

    function draw() {
        requestAnimationFrame(draw);
        ctx.clearRect(0, 0, canvas.width, canvas.height);
        if (state === "idle" || state === "thinking") {
            drawFlatLine();
            return;
        }
        analyser.getByteTimeDomainData(dataArray);
        ctx.lineWidth = 3;
        ctx.strokeStyle = state === "user" ? "#e74c3c" : "#2ecc71";
        ctx.beginPath();
        const sliceWidth = canvas.width / bufferLength;
        let x = 0;
        for (let i = 0; i < bufferLength; i++) {
            const v = dataArray[i] / 128.0;
            const y = v * canvas.height / 2;
            if (i === 0) ctx.moveTo(x, y);
            else ctx.lineTo(x, y);
            x += sliceWidth;
        }
        ctx.lineTo(canvas.width, canvas.height / 2);
        ctx.stroke();
    }
    draw();
}

});
</script>

</body>
</html>
