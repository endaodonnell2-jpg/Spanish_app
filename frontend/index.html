<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Walkie-Talkie Chat</title>
<style>
  body {
    margin: 0;
    padding: 0;
    background-color: #f3f0eb; /* light beige */
    font-family: sans-serif;
    display: flex;
    flex-direction: column;
    align-items: center;
    height: 100vh;
    justify-content: center;
    overflow: hidden;
  }

  #sound-bar {
    width: 80%;
    height: 20px;
    background-color: grey;
    border-radius: 10px;
    margin-bottom: 20px;
    position: relative;
    overflow: hidden;
  }

  #sound-level {
    height: 100%;
    width: 0%;
    background-color: grey;
    transition: width 0.05s linear;
  }

  #transcript {
    width: 90%;
    height: 100px;
    background-color: #fff;
    border-radius: 10px;
    padding: 10px;
    overflow-y: auto;
    margin-bottom: 20px;
    box-sizing: border-box;
    font-size: 16px;
  }

  #hold-button {
    width: 70%;
    max-width: 300px;
    height: 60px;
    background-color: green;
    border: none;
    border-radius: 10px;
    color: white;
    font-size: 24px;
    font-weight: bold;
    display: flex;
    align-items: center;
    justify-content: center;
    touch-action: manipulation;
    user-select: none;
  }
</style>
</head>
<body>

<div id="sound-bar"><div id="sound-level"></div></div>
<div id="transcript"></div>
<button id="hold-button">HOLD</button>

<script>
let isHolding = false;
let userStream, audioContext, analyser, dataArray;
let aiPlaying = false;

// Initialize microphone
async function initMic() {
  userStream = await navigator.mediaDevices.getUserMedia({ audio: true });
  audioContext = new (window.AudioContext || window.webkitAudioContext)();
  const source = audioContext.createMediaStreamSource(userStream);
  analyser = audioContext.createAnalyser();
  analyser.fftSize = 256;
  source.connect(analyser);
  dataArray = new Uint8Array(analyser.frequencyBinCount);
}

// Update sound bar based on input
function updateSoundBar() {
  let level = 0;
  if (isHolding && analyser) {
    analyser.getByteFrequencyData(dataArray);
    level = Math.max(...dataArray) / 255;
    document.getElementById('sound-level').style.width = `${level * 100}%`;
    document.getElementById('sound-level').style.backgroundColor = 'red';
  } else if (aiPlaying) {
    // AI speaking: animate green
    level = Math.random() * 0.5 + 0.3; // simulate AI peaks
    document.getElementById('sound-level').style.width = `${level * 100}%`;
    document.getElementById('sound-level').style.backgroundColor = 'green';
  } else {
    document.getElementById('sound-level').style.width = `0%`;
    document.getElementById('sound-level').style.backgroundColor = 'grey';
  }
  requestAnimationFrame(updateSoundBar);
}

// Handle hold button press
const holdBtn = document.getElementById('hold-button');
holdBtn.addEventListener('mousedown', startHold);
holdBtn.addEventListener('touchstart', startHold);
holdBtn.addEventListener('mouseup', endHold);
holdBtn.addEventListener('touchend', endHold);

function startHold() {
  isHolding = true;
  holdBtn.style.backgroundColor = 'red';
  // start recording audio to send to backend
  startRecording();
}

function endHold() {
  isHolding = false;
  holdBtn.style.backgroundColor = 'green';
  stopRecordingAndSend();
}

// Placeholder functions: implement with your backend
let mediaRecorder, audioChunks;
async function startRecording() {
  audioChunks = [];
  mediaRecorder = new MediaRecorder(userStream);
  mediaRecorder.ondataavailable = e => audioChunks.push(e.data);
  mediaRecorder.start();
}

async function stopRecordingAndSend() {
  mediaRecorder.stop();
  mediaRecorder.onstop = async () => {
    const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
    const formData = new FormData();
    formData.append('file', audioBlob);
    
    // send to backend
    const res = await fetch('/process_audio', { method: 'POST', body: formData });
    const data = await res.json();
    
    // show transcript
    const transcriptDiv = document.getElementById('transcript');
    transcriptDiv.innerHTML = `<p><strong>You:</strong> ${data.user_text}</p>
                               <p><strong>AI:</strong> ${data.ai_text}</p>`;
    
    // play AI audio
    aiPlaying = true;
    const aiAudio = new Audio(data.ai_audio_url);
    aiAudio.onended = () => aiPlaying = false;
    aiAudio.play();
  };
}

initMic();
updateSoundBar();
</script>

</body>
</html>
