import streamlit as st
import streamlit.components.v1 as components
import base64

st.title("üéôÔ∏è Real WhatsApp-Style Hold")

# This CSS creates the circular green button and the "pulse" animation
st.markdown("""
<style>
    .mic-wrap { display: flex; justify-content: center; padding: 20px; }
    #record-btn {
        width: 80px; height: 80px; border-radius: 50%;
        background-color: #00a884; border: none; cursor: pointer;
        display: flex; align-items: center; justify-content: center;
        transition: all 0.2s; user-select: none; -webkit-user-select: none;
    }
    #record-btn:active { background-color: #f15c5c; transform: scale(1.1); }
    .mic-icon { fill: white; width: 40px; height: 40px; }
</style>
""", unsafe_allow_html=True)

# The JavaScript Magic
# 1. Listen for mousedown -> Start MediaRecorder
# 2. Listen for mouseup -> Stop MediaRecorder -> Send data to Streamlit
record_js = """
<div class="mic-wrap">
    <button id="record-btn">
        <svg class="mic-icon" viewBox="0 0 24 24"><path d="M12 14c1.66 0 3-1.34 3-3V5c0-1.66-1.34-3-3-3S9 3.34 9 5v6c0 1.66 1.34 3 3 3z"/><path d="M17 11c0 2.76-2.24 5-5 5s-5-2.24-5-5H5c0 3.53 2.61 6.43 6 6.92V21h2v-3.08c3.39-.49 6-3.39 6-6.92h-2z"/></svg>
    </button>
</div>

<script>
    const btn = document.getElementById('record-btn');
    let mediaRecorder;
    let audioChunks = [];

    btn.addEventListener('mousedown', async () => {
        audioChunks = [];
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        mediaRecorder = new MediaRecorder(stream);
        mediaRecorder.ondataavailable = e => audioChunks.push(e.data);
        mediaRecorder.onstop = async () => {
            const blob = new Blob(audioChunks, { type: 'audio/wav' });
            const reader = new FileReader();
            reader.readAsDataURL(blob);
            reader.onloadend = () => {
                const base64String = reader.result.split(',')[1];
                window.parent.postMessage({
                    type: 'streamlit:set_widget_value',
                    data: base64String,
                    key: 'audio_data'
                }, '*');
            };
        };
        mediaRecorder.start();
    });

    btn.addEventListener('mouseup', () => {
        if (mediaRecorder && mediaRecorder.state === "recording") {
            mediaRecorder.stop();
        }
    });
    
    // Safety: stop if mouse leaves button
    btn.addEventListener('mouseleave', () => {
        if (mediaRecorder && mediaRecorder.state === "recording") {
            mediaRecorder.stop();
        }
    });
</script>
"""

# Render the component
# We use a dummy key in the JS (audio_data) to capture the base64 string
components.html(record_js, height=150)

# 3. Retrieve the audio from the JS component
# Streamlit's query_params or session_state trick is needed here
if "audio_data" not in st.session_state:
    st.session_state.audio_data = None

# Checking if new audio came in via the component
# Note: In a real app, you'd use a custom component library for cleaner data passing
# But for a "quick cook," we can check the state.
st.write("Hold button to record. Release to stop.")

# Handle the data sent from JavaScript
# Since we are using postMessage, we need a small listener or a proper component.
# For simplicity in a single file, here is the playback if data exists:
audio_input = st.chat_input("Or type here...") # Just to keep the UI clean

# To display the playback, we can use a workaround or 
# a simple st.audio if you save the base64 to a file.
# For now, this is the UI and Trigger logic.
